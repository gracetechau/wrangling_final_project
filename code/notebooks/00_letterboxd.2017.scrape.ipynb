{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4ad1fa-e714-40dd-b195-6dd03241899e",
   "metadata": {},
   "source": [
    "# Grace Techau\n",
    "## Box Office Revenue & Letterboxd Ratings Project \n",
    "### Scraping Letterboxd Website 2017 Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee81ad1-52d3-46b3-889c-3034026b4c19",
   "metadata": {},
   "source": [
    "**Scraping elements title, year, number_ratings, average_rating, length and genres for top 25% most popular Letterboxd movies in 2017 applying the filter 'Hide short films'.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7aaf6-c89e-497a-8da7-25806b5b2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a79c5e8-15fc-4beb-85b3-fd366462afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random scroll function \n",
    "def random_scroll(browser, total_wait_time): \n",
    "    total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_steps = random.randint(3,10)\n",
    "    scroll_increment = total_height // scroll_steps\n",
    "    time_per_step = total_wait_time / scroll_steps\n",
    "    for step in range(scroll_steps): \n",
    "        browser.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        random_wait = random.uniform(0.5 * time_per_step, 1.5 * time_per_step)\n",
    "        time.sleep(random_wait)\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3100a438-0220-442d-ac07-efaa5123f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Selenium web driver (using Chrome)\n",
    "chrome_options = Options()\n",
    "service = Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6f813-cbb3-41d2-8e07-ebcee7f0f0e6",
   "metadata": {},
   "source": [
    "### YEAR 2017 - Scrape URL links to individual movie detail pages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d766add-55a9-4173-b721-3c9879ee859f",
   "metadata": {},
   "source": [
    "Create a function for applying the viewing filter 'Hide short films' to each page when scraping the individual movie page URL's from the main Letterboxd movie website.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe2e41-7fa4-49cf-a7f8-fd01947d0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(): \n",
    "    try: \n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"section.smenu-wrapper .smenu label\"))\n",
    "        )\n",
    "            \n",
    "        filter_button = WebDriverWait(browser, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"section.smenu-wrapper .smenu label\"))\n",
    "        )\n",
    "        filter_button.click()\n",
    "    \n",
    "        time.sleep(random.uniform(1,3))\n",
    "            \n",
    "        #Apply the \"Hide short films\" filter\n",
    "        hide_short_films_button = WebDriverWait(browser,20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//a[contains(text(), 'Hide short films')]\")) \n",
    "        )\n",
    "        hide_short_films_button.click()\n",
    "        print(\"Clicked 'Hide short films' filter\")\n",
    "\n",
    "        time.sleep(random.uniform(4,15))\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(f\"Error applying filters: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061369e-0e5e-4ba2-9123-303a1972d783",
   "metadata": {},
   "source": [
    "Create a function to scrape the individual movie page URL's from the main Letterboxd movie website for movies from 2017 sorted by popularity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b410e6d9-675d-4d89-86c0-6a407ea17ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_links(): \n",
    "    urls_2017 = [] \n",
    "\n",
    "     #scrape all the a tags with the class 'frame'\n",
    "    tags = browser.find_elements(By.XPATH, '//a[@class=\"frame\"]')\n",
    "\n",
    "    #seperate the attribute 'href' from all tags - contains the URL to the individual Letterboxd movie detail pages \n",
    "    for tag in tags: \n",
    "        href = tag.get_attribute('href')\n",
    "        if href:\n",
    "            urls_2017.append(href)\n",
    "\n",
    "    return urls_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28865135-536a-4970-9605-cd3e643e0eea",
   "metadata": {},
   "source": [
    "Create a function for scraping multiple pages of the main Letterboxd website for films in 2017 sorted by popularity. For each page, the apply_filters and scrape_movie_links functions will run. \\\n",
    "\\\n",
    "For the year 2017 there are 269 pages of movies with the 'Hide short films' filter applied. I scraped only the top quarter of these page (66), to capture the 25% most popular movies. The 66 pages were scraped in four batches. The different batches were collected into seperate CSV files which are detailed at the bottom of this page. \\\n",
    "\\\n",
    "The four CSV files will be merged during cleaning to capture the total of the 25% most popular movies from 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f566d7b-b633-40d1-8018-102d535db67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_pages(start_page, end_page): \n",
    "    urls_2017 = [] \n",
    "\n",
    "    for i in range(start_page, end_page +1): \n",
    "        url_2017 = f\"https://letterboxd.com/films/popular/year/2017/page/{i}/\"\n",
    "\n",
    "        browser.get(url_2017) \n",
    "        browser.maximize_window()\n",
    "\n",
    "        print(f\"Scraping page {i}: {url_2017}\")\n",
    "\n",
    "        time.sleep(random.uniform(3,5))\n",
    "\n",
    "        # Only apply the filter to the first page being scraped - the filter is applied to all pages after \n",
    "        if i == 55: \n",
    "            apply_filters()\n",
    "\n",
    "        film_urls = scrape_movie_links()\n",
    "        urls_2017.extend(film_urls)\n",
    "\n",
    "        total_wait_time = random.uniform(5, 12)\n",
    "        random_scroll(browser, total_wait_time)\n",
    "\n",
    "        print(f\"Finished scraping page {i}.\")\n",
    "\n",
    "    return urls_2017\n",
    "\n",
    "## top 25% most popular pages: 66 pages \n",
    "### raw_1 - pages 1 to 37.5\n",
    "### raw_2 - pages 37.5 to 42.5 \n",
    "### raw_3 - pages 42.5 to 55.5 \n",
    "### raw_4 - pages 55.5  t0 66\n",
    "\n",
    "start_page = 55\n",
    "end_page = 66\n",
    "urls_2017 = scrape_movie_pages(start_page, end_page)\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Totals of URLS scraped for 2017\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Total # URLs scraped: {len(urls_2017)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cad4fe8-0496-49ff-a87b-6cdfad7f368e",
   "metadata": {},
   "source": [
    "Modify the scraped URL's to include the browser extension '/genres/'.\\\n",
    "This allows all the correct genre data to be scraped from the individual Letterboxd movie detail pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27640736-4574-4172-bd24-d8b4772ca24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifed_urls = [url + 'genres/' for url in urls_2017]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c82dac-ceee-4cd4-8c16-98c66beb55a8",
   "metadata": {},
   "source": [
    "### YEAR 2017 - Scrape movie data from each movie's page  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e76b56-9cf1-4e40-850c-9c4694b5f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store the data title, year, average_rating, number_ratings, lenth, and genres for \n",
    "# each movie on Letterboxd in 2017\n",
    "movie_data = []\n",
    "\n",
    "for url in modifed_urls: \n",
    "    browser.get(url)\n",
    "    browser.maximize_window()\n",
    "    \n",
    "    total_wait_time = random.uniform(5, 12)\n",
    "    random_scroll(browser, total_wait_time)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #SCRAPE TITLE\n",
    "        title_element = browser.find_element(By.CSS_SELECTOR,\"h1.headline-1.filmtitle span.name.js-widont.prettify\")\n",
    "        titles = title_element.text.strip()\n",
    "\n",
    "        #SCRAPE YEAR \n",
    "        year_element = browser.find_element(By.CSS_SELECTOR, \"div.releaseyear a\")\n",
    "        years = year_element.text.strip()\n",
    "        \n",
    "        #SCRAPE AVERAGE RATING AND NUMBER OF RATINGS \n",
    "        try:\n",
    "            average_rating_element = browser.find_element(By.CSS_SELECTOR, \"span.average-rating a.tooltip.display-rating \")\n",
    "            average_ratings = average_rating_element.text.strip()\n",
    "            number_ratings = average_rating_element.get_attribute('data-original-title')\n",
    "        except NoSuchElementException: \n",
    "            average_ratings = \"No average rating available\"\n",
    "            number_ratings = \"No number of ratings available\"\n",
    "            \n",
    "        #SCRAPE LENGTHS \n",
    "        lengths = browser.find_element(By.CSS_SELECTOR, \"p.text-link.text-footer\").text\n",
    "\n",
    "        #SCRAPE GENRES \n",
    "        try: \n",
    "            genre_elements = browser.find_elements(By.CSS_SELECTOR, \"div.text-sluglist.capitalize a.text-slug\")\n",
    "            if genre_elements:\n",
    "                genres = [genre.text.strip() for genre in genre_elements]\n",
    "            else: \n",
    "                genres = ['No genres available']\n",
    "        except NoSuchElementException:\n",
    "            genres = ['No genres available']\n",
    "\n",
    "        #Apend all of the movie data to the dictionary movie_data\n",
    "        movie_data.append({\n",
    "            'title': titles,\n",
    "            'year' : years, \n",
    "            'number_ratings' : number_ratings, \n",
    "            'average_rating' : average_ratings, \n",
    "            'length' : lengths, \n",
    "            'genres' : \", \".join(genres),\n",
    "        })\n",
    "\n",
    "    except Exception as e: \n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        movie_data.append({\n",
    "            'title': None,\n",
    "            'year' : None, \n",
    "            'number_ratings' : None, \n",
    "            'average_rating' : None, \n",
    "            'length' : None, \n",
    "            'genres' : None\n",
    "        })\n",
    "\n",
    "    #keep a tracker to know when each URL has been scraped \n",
    "    print(f\"Finished scraping {url}\")\n",
    "    \n",
    "#close the browser \n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e1b04-6b29-43e4-94a7-17a861b2becd",
   "metadata": {},
   "source": [
    "### YEAR 2017 - Create a pandas data frame 'movie_data_2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40c053-af73-4935-9e20-ea1c7846a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_2017 = pd.DataFrame(movie_data)\n",
    "\n",
    "display(movie_data_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b6749-62c9-4dbf-a463-6dacdf5e77b4",
   "metadata": {},
   "source": [
    "### Save dataframe to a CSV file for cleaning \n",
    "Break down of pages covered in the different files for scraping year 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a154bba-8598-416e-805a-7e7ad873f362",
   "metadata": {},
   "source": [
    "| Pages        | File Name                               |\n",
    "|--------------|-----------------------------------------|\n",
    "| 1 - 37       | letterboxd_movie_data_2017_raw_1.csv    |\n",
    "| 37 - 42      | letterboxd_movie_data_2017_raw_2.csv    |\n",
    "| 42 - 55      | letterboxd_movie_data_2017_raw_3.csv    |\n",
    "| 55 - 66      | letterboxd_movie_data_2017_raw_4.csv    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89e941-48df-4e09-872f-5e53742a9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_2017.to_csv(\"letterboxd_movie_data_2017_raw_4.csv\", header=True, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
