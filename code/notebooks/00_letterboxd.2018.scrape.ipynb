{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e76741c-60c1-4079-aa3f-63d09925e2c8",
   "metadata": {},
   "source": [
    "# Grace Techau\n",
    "## Box Office Revenue & Letterboxd Ratings Project \n",
    "### Scraping Letterboxd Website 2018 Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e11c101-9e08-4365-8d3f-03e63d9f8046",
   "metadata": {},
   "source": [
    "**Scraping elements title, year, number_ratings, average_rating, length and genres for top 25% most popular Letterboxd movies in 2018 applying the filter 'Hide short films'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd5b23-5b60-465c-9bff-b7e84c827a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages \n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1b506-2a01-45c6-b51f-212c5c9e54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random scroll function \n",
    "def random_scroll(browser, total_wait_time): \n",
    "    total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    scroll_steps = random.randint(3,10)\n",
    "    scroll_increment = total_height // scroll_steps\n",
    "    time_per_step = total_wait_time / scroll_steps\n",
    "    for step in range(scroll_steps): \n",
    "        browser.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        random_wait = random.uniform(0.5 * time_per_step, 1.5 * time_per_step)\n",
    "        time.sleep(random_wait)\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac5b75b-a420-467a-95a8-1e7de42b9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Selenium web driver (using Chrome)\n",
    "chrome_options = Options()\n",
    "service = Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=service, options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de11600-1373-4a54-b31c-7f75f4997598",
   "metadata": {},
   "source": [
    "### YEAR 2018 - Scrape URL links to individual movie detail pages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061448e-1c29-4bdb-ae95-024b884f4413",
   "metadata": {},
   "source": [
    "Create a function for applying the viewing filter 'Hide short films' to each page when scraping the individual movie page URL's from the main Letterboxd movie website.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e7458-172f-45a8-9ddc-6e182dd41dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(): \n",
    "    try: \n",
    "        WebDriverWait(browser, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"section.smenu-wrapper .smenu label\"))\n",
    "        )\n",
    "            \n",
    "        filter_button = WebDriverWait(browser, 20).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"section.smenu-wrapper .smenu label\"))\n",
    "        )\n",
    "        filter_button.click()\n",
    "    \n",
    "        time.sleep(random.uniform(1,3))\n",
    "            \n",
    "        #Apply the \"Hide short films\" filter\n",
    "        hide_short_films_button = WebDriverWait(browser,20).until(\n",
    "            EC.presence_of_element_located((By.XPATH, \"//a[contains(text(), 'Hide short films')]\")) \n",
    "        )\n",
    "        hide_short_films_button.click()\n",
    "        print(\"Clicked 'Hide short films' filter\")\n",
    "\n",
    "        time.sleep(random.uniform(4,15))\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(f\"Error applying filters: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97ec66-2f68-4606-b5c8-7ee98accebcb",
   "metadata": {},
   "source": [
    "Create a function to scrape the individual movie page URL's from the main Letterboxd movie website for movies from 2018 sorted by popularity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41584373-cb9b-43d3-b764-6108a6877db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_links(): \n",
    "    urls_2018 = [] \n",
    "\n",
    "     #scrape all the a tags with the class 'frame'\n",
    "    tags = browser.find_elements(By.XPATH, '//a[@class=\"frame\"]')\n",
    "\n",
    "    #seperate the attribute 'href' from all tags - contains the URL to the individual Letterboxd movie detail pages \n",
    "    for tag in tags: \n",
    "        href = tag.get_attribute('href')\n",
    "        if href:\n",
    "            urls_2018.append(href)\n",
    "\n",
    "    return urls_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147fa545-39a6-4c7c-8eea-49d0dcf3220f",
   "metadata": {},
   "source": [
    "Create a function for scraping multiple pages of the main Letterboxd website for films in 2018 sorted by popularity. For each page, the apply_filters and scrape_movie_links functions will run. \\\n",
    "\\\n",
    "For the year 2018 there are 285 pages of movies with the 'Hide short films' filter applied. I scraped only the top quarter of these page (71), to capture the 25% most popular movies. The 71 pages were scraped in three batches. The different batches were collected into seperate CSV files which are detailed at the bottom of this page. \\\n",
    "\\\n",
    "The three CSV files will be merged during cleaning to capture the total of the 25% most popular movies from 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03098f-ff95-477f-9030-92b71a6ee8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_pages(start_page, end_page): \n",
    "    urls_2018 = [] \n",
    "\n",
    "    for i in range(start_page, end_page +1): \n",
    "        url_2018 = f\"https://letterboxd.com/films/popular/year/2018/page/{i}/\"\n",
    "\n",
    "        browser.get(url_2018) \n",
    "        browser.maximize_window()\n",
    "\n",
    "        print(f\"Scraping page {i}: {url_2018}\")\n",
    "\n",
    "        time.sleep(random.uniform(3,5))\n",
    "\n",
    "        # Only apply the filter to the first page being scraped - the filter is applied to all pages after \n",
    "        if i == 39: \n",
    "            apply_filters()\n",
    "\n",
    "        film_urls = scrape_movie_links()\n",
    "        urls_2018.extend(film_urls)\n",
    "\n",
    "        total_wait_time = random.uniform(5, 12)\n",
    "        random_scroll(browser, total_wait_time)\n",
    "\n",
    "        print(f\"Finished scraping page {i}.\")\n",
    "\n",
    "    return urls_2018\n",
    "\n",
    "## top 25% most popular pages : 71 pages \n",
    "#### raw_1 - pages 1 to 35\n",
    "#### raw_2 - pages 36 to 39.5\n",
    "#### raw_3 - pages 39.5 to 71 \n",
    "\n",
    "start_page = 39\n",
    "end_page = 71\n",
    "urls_2018 = scrape_movie_pages(start_page, end_page)\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Totals of URLS scraped for 2018\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Total # URLs scraped: {len(urls_2018)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e7eeb-aa4b-4a53-be58-d23df352e130",
   "metadata": {},
   "source": [
    "Modify the scraped URL's to include the browser extension '/genres/'.\\\n",
    "This allows all the correct genre data to be scraped from the individual Letterboxd movie detail pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee958a-6ced-426e-a78c-116edacdecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "modifed_urls = [url + 'genres/' for url in urls_2018]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadbc8e-98e0-4646-8e81-f8cfd360c3c7",
   "metadata": {},
   "source": [
    "### YEAR 2018 - Scrape movie data from each movie's page  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c5465-07bc-4199-b054-9fb50977258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to store the data title, year, average_rating, number_ratings, lenth, and genres for \n",
    "# each movie on Letterboxd in 2018\n",
    "movie_data = []\n",
    "\n",
    "for url in modifed_urls: \n",
    "    browser.get(url)\n",
    "    browser.maximize_window()\n",
    "    \n",
    "    total_wait_time = random.uniform(5, 12)\n",
    "    random_scroll(browser, total_wait_time)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        #SCRAPE TITLE\n",
    "        title_element = browser.find_element(By.CSS_SELECTOR,\"h1.headline-1.filmtitle span.name.js-widont.prettify\")\n",
    "        titles = title_element.text.strip()\n",
    "\n",
    "        #SCRAPE YEAR \n",
    "        year_element = browser.find_element(By.CSS_SELECTOR, \"div.releaseyear a\")\n",
    "        years = year_element.text.strip()\n",
    "        \n",
    "        #SCRAPE AVERAGE RATING AND NUMBER OF RATINGS \n",
    "        try:\n",
    "            average_rating_element = browser.find_element(By.CSS_SELECTOR, \"span.average-rating a.tooltip.display-rating \")\n",
    "            average_ratings = average_rating_element.text.strip()\n",
    "            number_ratings = average_rating_element.get_attribute('data-original-title')\n",
    "        except NoSuchElementException: \n",
    "            average_ratings = \"No average rating available\"\n",
    "            number_ratings = \"No number of ratings available\"\n",
    "            \n",
    "        #SCRAPE LENGTHS \n",
    "        lengths = browser.find_element(By.CSS_SELECTOR, \"p.text-link.text-footer\").text\n",
    "\n",
    "        #SCRAPE GENRES \n",
    "        try: \n",
    "            genre_elements = browser.find_elements(By.CSS_SELECTOR, \"div.text-sluglist.capitalize a.text-slug\")\n",
    "            if genre_elements:\n",
    "                genres = [genre.text.strip() for genre in genre_elements]\n",
    "            else: \n",
    "                genres = ['No genres available']\n",
    "        except NoSuchElementException:\n",
    "            genres = ['No genres available']\n",
    "\n",
    "        #Apend all of the movie data to the dictionary movie_data\n",
    "        movie_data.append({\n",
    "            'title': titles,\n",
    "            'year' : years, \n",
    "            'number_ratings' : number_ratings, \n",
    "            'average_rating' : average_ratings, \n",
    "            'length' : lengths, \n",
    "            'genres' : \", \".join(genres),\n",
    "        })\n",
    "\n",
    "    except Exception as e: \n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        movie_data.append({\n",
    "            'title': None,\n",
    "            'year' : None, \n",
    "            'number_ratings' : None, \n",
    "            'average_rating' : None, \n",
    "            'length' : None, \n",
    "            'genres' : None\n",
    "        })\n",
    "\n",
    "    #keep a tracker to know when each URL has been scraped \n",
    "    print(f\"Finished scraping {url}\")\n",
    "    \n",
    "#close the browser \n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3453d2da-315a-4d48-b4a8-b5c1a717dd97",
   "metadata": {},
   "source": [
    "### YEAR 2018 - Create a pandas data frame 'movie_data_2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fd9d7-3376-44da-aa9b-3439718f3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_2018 = pd.DataFrame(movie_data)\n",
    "\n",
    "display(movie_data_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d42544-3580-46b9-a7d1-e8199babea8a",
   "metadata": {},
   "source": [
    "### Save dataframe to a CSV file for cleaning \n",
    "Break down of pages covered in the different files for scraping year 2018. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a4d77-61e2-4279-9dad-6222f61bbc08",
   "metadata": {},
   "source": [
    "| Pages             | File Name                         |\n",
    "|-------------------|-----------------------------------|\n",
    "| Pages 1 - 35      | letterboxd_movie_data_2018_raw_1.csv |\n",
    "| Pages 36 - 39.5   | letterboxd_movie_data_2018_raw_2.csv |\n",
    "| Pages 39.5 - 71   | letterboxd_movie_data_2018_raw_3.csv |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f7e86-1100-487e-ad66-d04d0db8ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data_2018.to_csv(\"letterboxd_movie_data_2018_raw_3.csv\", header=True, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
